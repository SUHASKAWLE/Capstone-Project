{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir6VDV9Xrsnl"
   },
   "source": [
    "# **Effect of this proposal**\n",
    "\n",
    "**Brief Introduction**\n",
    "\n",
    "* A bank's credit card department is one of the top adopters of data science. A top focus for the bank has always been acquiring new credit card customers. Giving out credit cards without doing proper research or evaluating applicants' creditworthiness is quite risky. The credit card department has been using a data-driven system for credit assessment called Credit Scoring for many years, and the model is known as an application scorecard. A credit card application's cutoff value is determined using the application scorecard, which also aids in estimating the applicant's level of risk. This decision is made based on strategic priority at a given time.\n",
    "\n",
    "\n",
    "* Customers must fill out a form, either physically or online, to apply for a credit card. The application data is used to evaluate the applicant's creditworthiness. The decision is made using the application data in addition to the Credit Bureau Score, such as the FICO Score in the US or the CIBIL Score in India, and other internal information on the applicants. Additionally, the banks are rapidly taking a lot of outside data into account to enhance the caliber of credit judgements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1G2yuQ1t31n"
   },
   "source": [
    "# **1. Getting the data :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ce71a7f"
   },
   "source": [
    "### Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "260575b4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5271b3f8"
   },
   "source": [
    "### Data collection and Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f5ebffa"
   },
   "outputs": [],
   "source": [
    "# Loading the credit card data from csv file to pandas dataframe\n",
    "\n",
    "Credit_card = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\CapstoneProject\\Credit_card.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "be0a787a",
    "outputId": "7e2aed9a-861b-4967-8193-a99a90fec804"
   },
   "outputs": [],
   "source": [
    "# Inspecting the first 5 rows of the credit card dataframe\n",
    "\n",
    "Credit_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae9b3584",
    "outputId": "0573988c-394c-419c-de4f-66bbb6666c96"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns of dataset\n",
    "\n",
    "Credit_card.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "da0eeadd"
   },
   "outputs": [],
   "source": [
    "# Loading the credit card label data from csv file to pandas dataframe\n",
    "\n",
    "Credit_card_label = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\CapstoneProject\\Credit_card_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3b053755",
    "outputId": "23d93465-0ecc-4340-c6e6-f95e67282a62"
   },
   "outputs": [],
   "source": [
    "# Inspecting the first 5 rows of the credit card label dataframe\n",
    "\n",
    "Credit_card_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f2a06d9",
    "outputId": "d04ee227-5caa-40f3-d4ce-86a5ddab77ba"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns of dataset\n",
    "\n",
    "Credit_card_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "6e329835",
    "outputId": "9f004943-dda1-4d35-f7d5-39901fa55eb0"
   },
   "outputs": [],
   "source": [
    "# To Join both the table common column IND_ID is used\n",
    "\n",
    "credit_card = pd.merge(Credit_card, Credit_card_label, on='Ind_ID', how='outer')\n",
    "# outer includes all rows from both Credit_card and Credit_card_label, with NaN values in any columns where data is missing.\n",
    "\n",
    "# Inspecting the first 5 rows of the complete dataframe\n",
    "\n",
    "credit_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfENwY8BSJnD"
   },
   "outputs": [],
   "source": [
    "credit_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0981643a",
    "outputId": "2e24e3da-4a59-482c-c75c-dee15451cafd"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns of dataset\n",
    "\n",
    "credit_card.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a01386c",
    "outputId": "0ef0653d-0379-4193-a494-a9a5c89c1de5"
   },
   "outputs": [],
   "source": [
    "# Getting Some information about dataset\n",
    "\n",
    "credit_card.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJEe8WhdsQ79"
   },
   "source": [
    "# **Variable/Features information:**\n",
    "\n",
    "Features name: (Credit_Card.csv)\n",
    "\n",
    "Ind_ID: Client ID\n",
    "\n",
    "Gender: Gender information\n",
    "\n",
    "Car_owner: Having car or not\n",
    "\n",
    "Propert_owner: Having property or not\n",
    "\n",
    "Children: Count of children\n",
    "\n",
    "Annual_income: Annual income\n",
    "\n",
    "Type_Income: Income type\n",
    "\n",
    "Education: Education level\n",
    "\n",
    "Marital_status: Marital_status\n",
    "\n",
    "Housing_type: Living style\n",
    "\n",
    "Birthday_count: Use backward count from current day (0), -1 means yesterday.\n",
    "\n",
    "Employed_days: Start date of employment. Use backward count from current day (0). Positive value means, individual is currently unemployed.\n",
    "\n",
    "Mobile_phone: Any mobile phone\n",
    "\n",
    "Work_phone: Any work phone\n",
    "\n",
    "Phone: Any phone number\n",
    "\n",
    "EMAIL_ID: Any email ID\n",
    "\n",
    "Type_Occupation: Occupation\n",
    "\n",
    "Family_Members: Family size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ID: The joining key between application data and credit status data, same is Ind_ID\n",
    "\n",
    "Label: 0 is application approved and 1 is application rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtzYDlx5uI9Y"
   },
   "source": [
    "# **2. Identifying The Problem :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mk8fxCO26cmx"
   },
   "source": [
    "## **i. Label Imbalanced Data :**\n",
    "\n",
    "Hypothesis 1 :\n",
    "* Dataset is not an imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNJbkRbMFeSW",
    "outputId": "44049249-628e-4d79-9056-8f2f2cd1fe79"
   },
   "outputs": [],
   "source": [
    "Credit_card_label['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3eOa6JDFnHV",
    "outputId": "faca0f1d-48de-4cfc-f23d-65d364469824"
   },
   "outputs": [],
   "source": [
    "Credit_card_label['label'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "5LTAnQsp5Qc3",
    "outputId": "0f9c5f82-8943-486d-add4-f6e6ca8ae36b"
   },
   "outputs": [],
   "source": [
    "# Calculate the class frequencies as percentages\n",
    "class_frequencies = Credit_card_label['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Plot the bar chart\n",
    "ax = class_frequencies.plot(kind='bar', rot=0)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for i, v in enumerate(class_frequencies):\n",
    "    ax.text(i, v, f'{v:.1f}', ha='center', va='bottom')\n",
    "\n",
    "# Set title and axis labels\n",
    "plt.title('Label Class Frequencies')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jsksbpwU6rJ"
   },
   "source": [
    "**Here From Above output The values of label \"Yes\" is 88.7 % and values of label \"No\" is 11.3 %.**\n",
    "\n",
    "**So it is an Imbalanced Dataset ,i.e, Biased towards Yes Values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AT0WnNg6oru"
   },
   "source": [
    "## **ii. Missing/Null Values :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8a57192",
    "outputId": "6026efee-21f3-48ce-e870-d82fa2e48d8e"
   },
   "outputs": [],
   "source": [
    "# Checking the missing values\n",
    "\n",
    "credit_card.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17d717a2",
    "outputId": "f58166e3-3025-4a61-eedc-f65cc6b1e215"
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values in each column of the \"credit_card\" DataFrame.\n",
    "\n",
    "credit_card.isna().mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYD36boW7CxS"
   },
   "source": [
    "As All the missing values columns contains less than 5% missing data but for **Type_Occupation 31 % data is missing.**\n",
    "\n",
    "so we can use following strategies\n",
    "1. imputation\n",
    "2. deletion\n",
    "\n",
    "for that we need to first check in cases where **missingness itself holds important information** and may have an impact on the analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "s8lHR03d8JoW",
    "outputId": "300aa4d9-1d1f-4e4b-9736-b6a389c14f1a"
   },
   "outputs": [],
   "source": [
    "!pip install missingno\n",
    "import missingno as msno\n",
    "msno.matrix(credit_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elhfnaMFFLyx"
   },
   "source": [
    "This shows that missing values are not co-related with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bf-zQQEF-dwd"
   },
   "source": [
    "## **iii. Renaming :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb5c0c23"
   },
   "outputs": [],
   "source": [
    "# Renames the column 'Propert_Owner' to 'Property_Owner' within the DataFrame 'credit_card'.\n",
    "\n",
    "credit_card.rename(columns = {'Propert_Owner':'Property_Owner'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ofr0veNw-2mH"
   },
   "source": [
    "## **iv. value counts :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b99fcc74"
   },
   "outputs": [],
   "source": [
    "# 'EDUCATION' column of the 'credit_card' DataFrame from 'Secondary / secondary special' to 'Secondary'.\n",
    "\n",
    "credit_card.loc[credit_card['EDUCATION'] == 'Secondary / secondary special', 'EDUCATION'] = 'Secondary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11977d46",
    "outputId": "d12e5daa-2d30-4adc-f8cd-f24f31c0ba57"
   },
   "outputs": [],
   "source": [
    "# To returns a count of unique values in the 'EDUCATION' column of the DataFrame 'credit_card'.\n",
    "\n",
    "credit_card['EDUCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8515596",
    "outputId": "723aa771-b838-420d-e4d5-6563c736c889"
   },
   "outputs": [],
   "source": [
    "# To returns a count of unique values in the 'Housing_type' column of the DataFrame 'credit_card'.\n",
    "\n",
    "credit_card['Housing_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fa2f437a"
   },
   "outputs": [],
   "source": [
    "# Acedemic degree have only 2 entries, we can remove it as it won't affect the the model training\n",
    "\n",
    "credit_card = credit_card[credit_card['EDUCATION'] != 'Academic degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07bdaf43"
   },
   "outputs": [],
   "source": [
    "# Office apartment have only 9 entries, we can remove it as it won't affect the the model training\n",
    "\n",
    "credit_card = credit_card[credit_card['Housing_type'] != 'Office apartment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a59de8e8"
   },
   "outputs": [],
   "source": [
    "# Co-op apartment have only 5 entries, we can remove it as it won't affect the the model training\n",
    "\n",
    "credit_card = credit_card[credit_card['Housing_type'] != 'Co-op apartment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-JcXnEP_gTi"
   },
   "outputs": [],
   "source": [
    "credit_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1XwIPuM_Fy0S",
    "outputId": "2508436f-7cf9-4ef7-889c-9015797d7ec6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = credit_card.select_dtypes(include='number').columns\n",
    "categorical_columns = credit_card.select_dtypes(include='object').columns\n",
    "\n",
    "# # Perform one-hot encoding on categorical columns\n",
    "# encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "# encoded_data = pd.DataFrame(encoder.fit_transform(credit_card[categorical_columns]))\n",
    "# encoded_data.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "\n",
    "# Combine encoded data with numerical columns\n",
    "# processed_data = pd.concat([credit_card[numerical_columns], encoded_data], axis=1)\n",
    "\n",
    "print(\"Numerical Columns:\")\n",
    "print(numerical_columns)\n",
    "print(\"\\nCategorical Columns:\")\n",
    "print(categorical_columns)\n",
    "# print(\"\\nProcessed Data:\")\n",
    "# print(processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82191d8d"
   },
   "outputs": [],
   "source": [
    "# drops the columns from the 'credit_card' DataFrame, as 'Mobile_phone', 'Work_Phone', 'Phone', 'EMAIL_ID' not gonna affect,\n",
    "# label and 'Type_Occupation' have many missing values i.e 31.52%.\n",
    "\n",
    "credit_card.drop(['Mobile_phone', 'Work_Phone', 'Phone', 'EMAIL_ID', 'Type_Occupation'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97300868",
    "outputId": "4cc9d226-23e6-4920-fa11-814fb36ce7fc"
   },
   "outputs": [],
   "source": [
    "# Checking the missing values\n",
    "\n",
    "credit_card.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "d7e8b87b",
    "outputId": "14d9a091-222d-4bbf-b1fb-0060540f2613"
   },
   "outputs": [],
   "source": [
    "# removes the rows from the 'credit_card' DataFrame where the 'GENDER' column contains missing values\n",
    "\n",
    "column_to_check = 'GENDER'\n",
    "credit_card = credit_card.dropna(subset=[column_to_check])\n",
    "credit_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a957549f",
    "outputId": "bea00699-a66c-4e61-de78-efd762efb177"
   },
   "outputs": [],
   "source": [
    "# # Checking the missing values, we can see that missing values from GENDER column is removed.\n",
    "\n",
    "credit_card.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fbdae8a"
   },
   "source": [
    "### Imputation Using Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "696bc120"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries for knn\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_columns = ['Annual_income', 'Birthday_count']\n",
    "\n",
    "# Apply KNN imputation on numerical columns\n",
    "knn_imputer = KNNImputer()\n",
    "credit_card[numerical_columns] = knn_imputer.fit_transform(credit_card[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fe79154a"
   },
   "outputs": [],
   "source": [
    "credit_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ecb4dd2",
    "outputId": "2d8abb90-4039-47b8-e444-d2a15c12b8dc"
   },
   "outputs": [],
   "source": [
    "# Missing values is filled with KNN Imputation techniques\n",
    "\n",
    "credit_card.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebdb4d3d",
    "outputId": "a54d3117-86d5-4eed-a6eb-90c7fcbcc985"
   },
   "outputs": [],
   "source": [
    "# Getting Some information about dataset\n",
    "\n",
    "credit_card.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a36912f5"
   },
   "source": [
    "- We can see that all the missing values is filled and all the data types are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "113d7c97"
   },
   "source": [
    "- Here we can see that Annual_income and Employed_days have outliers which needs to be remove to clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1963a2b4",
    "outputId": "be73a2ed-83d5-4c93-9379-a92f14195193"
   },
   "outputs": [],
   "source": [
    "# To obtain the column names of the 'credit_card' DataFrame\n",
    "\n",
    "credit_card.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "9a5afb14",
    "outputId": "d8eb972c-2adb-41cf-a714-292e7d6b4fc7"
   },
   "outputs": [],
   "source": [
    "# To generates a summary statistics table for the 'credit_card' DataFrame, including both numerical and categorical columns.\n",
    "\n",
    "credit_card.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VKV73nnb07n"
   },
   "source": [
    "## **For SQL part:**\n",
    "* Creating a database named credit_card.sql to store all queries of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h01wRoNDMuUo"
   },
   "outputs": [],
   "source": [
    "credit_card.to_csv('credit_card_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WkbOHwRBYyYp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('credit_card_all.csv')\n",
    "\n",
    "# Get column names and data types from the DataFrame\n",
    "column_names = credit_card.columns\n",
    "data_types = credit_card.dtypes\n",
    "\n",
    "# Generate the CREATE TABLE statement\n",
    "create_table_query = f\"CREATE TABLE credit_card (\\n\"\n",
    "for column_name, data_type in zip(column_names, data_types):\n",
    "    if data_type == 'object':\n",
    "        data_type = 'VARCHAR(50)'  # Modify the maximum length as per your requirement\n",
    "    elif data_type == 'int64':\n",
    "        data_type = 'INT'\n",
    "    elif data_type == 'float64':\n",
    "        data_type = 'DECIMAL(10, 2)'  # Modify the precision and scale as per your requirement\n",
    "    create_table_query += f\"    {column_name} {data_type},\\n\"\n",
    "create_table_query = create_table_query.rstrip(',\\n') + '\\n);'\n",
    "\n",
    "# Generate the INSERT INTO statements\n",
    "insert_queries = []\n",
    "table_name = 'credit_card'\n",
    "\n",
    "for row in credit_card.itertuples(index=False):\n",
    "    values = ', '.join(f\"'{str(value)}'\" for value in row)\n",
    "    insert_query = f\"INSERT INTO {table_name} ({', '.join(column_names)}) VALUES ({values});\"\n",
    "    insert_queries.append(insert_query)\n",
    "\n",
    "# Generate the SELECT statement for column names\n",
    "select_column_names_query = f\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{table_name}';\"\n",
    "\n",
    "# Save the SQL queries to a file\n",
    "with open('credit_card_all_0.1.sql', 'w') as f:\n",
    "    f.write(create_table_query + '\\n\\n')\n",
    "    f.write('\\n'.join(insert_queries))\n",
    "    f.write('\\n\\n')\n",
    "    f.write(select_column_names_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb5dfce5"
   },
   "outputs": [],
   "source": [
    "# Drop rows where a column value meets a condition\n",
    "credit_card = credit_card[~(credit_card['CHILDREN'] == 14)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c412ecda"
   },
   "source": [
    "- 14 children is outlier so I remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iua7zCMxuZhA"
   },
   "source": [
    "# **3. Visualization :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yotIL6e2PCom"
   },
   "source": [
    "## **i. Distribution :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "E5k8SEUic6i_",
    "outputId": "eb8da449-a046-438f-b227-f6a93b7c16e4"
   },
   "outputs": [],
   "source": [
    "# Children column Distribution\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.countplot(x = \"CHILDREN\", data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('CHILDREN DISTRIBUTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "956e3dd0"
   },
   "source": [
    "- Most of the families prefer to have 0 Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "29b8b61f",
    "outputId": "b390318a-bf2a-4862-b3b5-c7e14cdc7e5e"
   },
   "outputs": [],
   "source": [
    "# Gender Distribution\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.countplot(x = \"GENDER\", data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('GENDER DISTRIBUTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "445d2cb3"
   },
   "source": [
    "- Number of Females are greater than Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "6023670c",
    "outputId": "7dd694f7-7055-452f-852c-f7b5b66f323d"
   },
   "outputs": [],
   "source": [
    "# Property_Owner Distribution\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.countplot(x = \"Property_Owner\", data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('PROPERTY OWNER DISTRIBUTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5598bbd"
   },
   "source": [
    "- Most of the people prefer to own Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "2e979630",
    "outputId": "8f2a679f-b858-4ba0-f998-65ceb03f9560"
   },
   "outputs": [],
   "source": [
    "# Car owner Distribution\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.countplot(x = \"Car_Owner\", data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('CAR OWNER DISTRIBUTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03ab73c0"
   },
   "source": [
    "- Most of the people do not prefer to own car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "4430c24c",
    "outputId": "16d63a47-90a9-44a3-a3ee-ea9937bd5f53"
   },
   "outputs": [],
   "source": [
    "# To generate a distribution of property ownership based on the gender of the owners in the 'credit_card' DataFrame\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.countplot(x = \"Property_Owner\", hue = 'GENDER', data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('PROPERTY OWNERSHIP BASED ON GENDER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1c6e695"
   },
   "source": [
    "- Most of the Females prefer to own property than males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "e2611855",
    "outputId": "ddcaa41e-3a2d-48ee-b48f-95905dda5bb2"
   },
   "outputs": [],
   "source": [
    "# To generate a distribution of Car ownership based on the gender of the owners in the 'credit_card' DataFrame\n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "ax = sns.countplot(x = \"Car_Owner\", hue = 'GENDER', data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('CAR OWNERSHIP BASED ON THE GENDER')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7198e52d"
   },
   "source": [
    "- Most of the Males prefer to own car and most of the females do not prefer to own car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "19bb806d",
    "outputId": "33de2068-fec9-4fec-e974-122c5e9f508f"
   },
   "outputs": [],
   "source": [
    "# Income type Distribution\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "ax = sns.countplot(x = \"Type_Income\", data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('INCOME TYPE DISTRIBUTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "115addc5"
   },
   "source": [
    "- The majority of individuals in the dataset have the income type of \"Working,\" with a count of 783. This suggests that a significant number of individuals in the dataset are actively employed.\n",
    "- The second most common income type is \"Commercial associate,\" with a count of 362. This indicates a sizable number of individuals who are associated with commercial activities or occupations.\n",
    "- The income type of \"Pensioner\" has a count of 267, suggesting that there is a notable presence of retired individuals in the dataset.\n",
    "- The income type of \"State servant\" has the lowest count among the mentioned categories, with 112 individuals falling into this group. This implies a relatively smaller representation of individuals employed in public service or government positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "650614fd",
    "outputId": "abab30a3-f822-41d9-a936-641193dece03"
   },
   "outputs": [],
   "source": [
    "# Education column Distribution\n",
    "\n",
    "plt.figure(figsize = (7,6))\n",
    "ax = sns.countplot(x = \"EDUCATION\", data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('EDUCATION DISTRIBUTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9033478"
   },
   "source": [
    "- The most common education type in the dataset is \"Secondary,\" with a count of 1018. This suggests that a significant number of individuals in the dataset have completed secondary education.\n",
    "- \"Higher education\" is the second most prevalent education type, with a count of 418. This indicates a considerable number of individuals with higher education qualifications.\n",
    "- The category \"Incomplete higher\" has a count of 67, indicating a smaller number of individuals who have pursued higher education but have not completed their studies.\n",
    "- The least common education type among the mentioned categories is \"Lower secondary,\" with a count of 21. This suggests a relatively smaller representation of individuals who have completed education up to the lower secondary level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "c008d18d",
    "outputId": "724099a0-8253-4b6a-d355-b4f4dbe7028e"
   },
   "outputs": [],
   "source": [
    "# Marital status column Distribution\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "ax = sns.countplot(x = \"Marital_status\", data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('MARITAL STATUS DISTRIBUTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "394e4db3"
   },
   "source": [
    "- Most of the people are married"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "6ffce024",
    "outputId": "bddae47a-f45a-4a28-f4b3-6f66871fdbeb"
   },
   "outputs": [],
   "source": [
    "# Housing type column Distribution\n",
    "\n",
    "plt.figure(figsize = (7,7))\n",
    "ax = sns.countplot(x = \"Housing_type\", data = credit_card)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Housing_type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5ecfa3b"
   },
   "source": [
    "- Most of the people are preferred to stay in House/apartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "132e577a",
    "outputId": "a0756105-47cb-466e-ff84-7db0d6426e60"
   },
   "outputs": [],
   "source": [
    "# To generate a plot that shows the distribution of annual incomes in the 'credit_card' DataFrame.\n",
    "# The histogram represents the distribution of incomes\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize = (6,6))\n",
    "sns.distplot(credit_card[\"Annual_income\"])\n",
    "plt.title('ANNUAL INCOME DISTRIBUTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed2f8e6d"
   },
   "source": [
    "* The data is right skewed so there are outliers present in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "bc1c4e83",
    "outputId": "1fa25f51-f303-42a1-bdd9-543780ae4bff"
   },
   "outputs": [],
   "source": [
    "# To generate a plot that shows the distribution of Birthday count in the 'credit_card' DataFrame.\n",
    "# The histogram represents the distribution of Birthday count\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize = (6,6))\n",
    "sns.distplot(credit_card[\"Birthday_count\"])\n",
    "plt.title('BIRTHDAY COUNT DISTRIBUTION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9x0_2vnPhgm"
   },
   "source": [
    "## **ii.  Checking For Outliers :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 852
    },
    "id": "dbdad634",
    "outputId": "81007cdd-d5e4-4c41-b91e-739f5396f059"
   },
   "outputs": [],
   "source": [
    "# create boxplot for each numerical column in the 'credit_card' DataFrame, displaying information about the\n",
    "# distribution and outliers for each column.\n",
    "\n",
    "credit_card.boxplot(figsize = (14,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d2890d0"
   },
   "source": [
    "- Annual Income, Employed days have outliers and we have to remove the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b049c56"
   },
   "source": [
    "### Removing outliers using IQR score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "78adf179",
    "outputId": "94e87516-945a-477c-fbdf-37bb4971c6ad"
   },
   "outputs": [],
   "source": [
    "# To plot a boxplot of the variable 'Annual_income' using the data from the 'credit_card' dataset\n",
    "\n",
    "sns.boxplot(y='Annual_income', data = credit_card)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed019e45"
   },
   "source": [
    "- We can see that Annual income have outliers and to make good prediction we need to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abeb7aea"
   },
   "outputs": [],
   "source": [
    "# To calculate the lower limit (LL) and upper limit (UL) for identifying/removing outliers using the Interquartile range method\n",
    "\n",
    "Q1 = credit_card['Annual_income'].quantile(0.25)\n",
    "Q3 = credit_card['Annual_income'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "LL = Q1 - (IQR * 1.5)\n",
    "UL = Q3 + (IQR * 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d49eb43e",
    "outputId": "92b2cde9-fa0e-4346-eb64-366cd8128e47"
   },
   "outputs": [],
   "source": [
    "# lower limit\n",
    "LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a21b8a41",
    "outputId": "076eb60f-fcdb-470f-ceb4-9ff0cd9dd872"
   },
   "outputs": [],
   "source": [
    "# Upper Limit\n",
    "UL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "5cda65e3",
    "outputId": "958dcb8d-7aaf-4203-a53b-ef58a4f23d1a"
   },
   "outputs": [],
   "source": [
    "# To filter the 'credit_card' dataset to exclude rows where the 'Annual_income' values are greater than the upper limit (UL)\n",
    "\n",
    "credit_card = credit_card[credit_card['Annual_income'] <= UL]\n",
    "credit_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "091cc9c6",
    "outputId": "2cf7b846-81ae-4f27-c909-1b7f59ef3952"
   },
   "outputs": [],
   "source": [
    "# To plot a boxplot of the variable 'Annual_income' using the data from the 'credit_card' dataset\n",
    "\n",
    "sns.boxplot(y='Annual_income', data = credit_card)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0d8eacc"
   },
   "source": [
    "- We have removed the outliers of Annual income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "5e9ea31a",
    "outputId": "4147b9cf-6ae9-408c-d55e-2cc91fd7ded4"
   },
   "outputs": [],
   "source": [
    "# To plot a boxplot of the variable 'Birthday_count' using the data from the 'credit_card' dataset\n",
    "\n",
    "sns.boxplot(y='Birthday_count', data = credit_card)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96d0611a"
   },
   "outputs": [],
   "source": [
    "credit_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "f2d395e3",
    "outputId": "5f1429b9-6e1e-4079-8c9b-e070331dd8e2"
   },
   "outputs": [],
   "source": [
    "# To plot a boxplot of the variable 'Employed_days' using the data from the 'credit_card' dataset\n",
    "\n",
    "sns.boxplot(y='Employed_days', data = credit_card)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69ecb93f"
   },
   "source": [
    "- Employed_days column have lot of outliers and to make good prediction we need to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9368ca83"
   },
   "outputs": [],
   "source": [
    "# To calculate the lower limit (LL) and upper limit (UL) for identifying/removing outliers using the Interquartile range method\n",
    "\n",
    "Q1 = credit_card['Employed_days'].quantile(0.25)\n",
    "Q3 = credit_card['Employed_days'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "LL = Q1 - (IQR * 1.5)\n",
    "UL = Q3 + (IQR * 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "654ee35f",
    "outputId": "db275ded-e315-47a1-c0c2-75313f7a6e37"
   },
   "outputs": [],
   "source": [
    "# Lower limit\n",
    "LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca8376e1",
    "outputId": "baac8e93-a1e5-4ea1-fe14-0748dc8bc7cc"
   },
   "outputs": [],
   "source": [
    "# Upper limit\n",
    "UL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5b70510"
   },
   "outputs": [],
   "source": [
    "# To filter the 'credit_card' dataset to exclude rows where the 'Employed_days' values are greater than the upper limit (UL)\n",
    "\n",
    "credit_card = credit_card[credit_card['Employed_days'] <= UL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76a87a01"
   },
   "outputs": [],
   "source": [
    "# To filter the 'credit_card' dataset to exclude rows where the 'Employed_days' values are less than the Lower limit (LL)\n",
    "\n",
    "credit_card = credit_card[credit_card['Employed_days'] >= LL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "71453db1",
    "outputId": "84059d1e-04f5-477a-d8c9-8bac93f8c792"
   },
   "outputs": [],
   "source": [
    "# To plot a boxplot of the variable 'Employed_days' using the data from the 'credit_card' dataset\n",
    "\n",
    "sns.boxplot(y='Employed_days', data = credit_card)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "379087b2"
   },
   "source": [
    "- We can see that we have removed most of the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "69c46860",
    "outputId": "8d904679-7588-477b-b5d8-fe5afbcb2e6e"
   },
   "outputs": [],
   "source": [
    "# To plot a boxplot of the variable 'Family_Members' using the data from the 'credit_card' dataset\n",
    "\n",
    "sns.boxplot(y='Family_Members', data = credit_card)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 852
    },
    "id": "1acfdb73",
    "outputId": "1cb7f2ad-79ef-411b-ba95-957425e365f3"
   },
   "outputs": [],
   "source": [
    "# create boxplot for each numerical column in the 'credit_card' DataFrame, displaying information about the\n",
    "# distribution and outliers for each column.\n",
    "\n",
    "credit_card.boxplot(figsize = (14,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "832255ea"
   },
   "source": [
    "- We can see that we have removed most of the outliers, which will help us to do good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "75eca4d3",
    "outputId": "210045f6-ac99-4020-95f3-62aefa0aca41"
   },
   "outputs": [],
   "source": [
    "# To create a boxplot of the 'Annual_income' variable in the 'credit_card' dataset, grouped by the 'GENDER'\n",
    "\n",
    "sns.boxplot(y='Annual_income', x='GENDER', data=credit_card)\n",
    "plt.xlabel('GENDER')\n",
    "plt.ylabel('Annual_income')\n",
    "plt.title('Boxplot of Annual Income by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04da487b"
   },
   "source": [
    "- Males have more Annual Income compared to Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "088e9feb",
    "outputId": "e5b41998-7991-49f8-f9c1-68c445391058"
   },
   "outputs": [],
   "source": [
    "# To create a boxplot of the 'Annual_income' variable in the 'credit_card' dataset, grouped by the 'Car_Owner'\n",
    "\n",
    "sns.boxplot(y='Annual_income', x='Car_Owner', data=credit_card)\n",
    "plt.xlabel('Car_Owner')\n",
    "plt.ylabel('Annual_income')\n",
    "plt.title('Boxplot of Annual Income by Car_Owner')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd407c03"
   },
   "source": [
    "- People having car tends to have higher Annual Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "62bddc98",
    "outputId": "084372a3-357f-4186-effb-a6a7faa3e26a"
   },
   "outputs": [],
   "source": [
    "# To create a boxplot of the 'Annual_income' variable in the 'credit_card' dataset, grouped by the 'Property_Owner'\n",
    "\n",
    "sns.boxplot(y='Annual_income', x='Property_Owner', data=credit_card)\n",
    "plt.xlabel('Property_Owner')\n",
    "plt.ylabel('Annual_income')\n",
    "plt.title('Boxplot of Annual Income by Property_Owner')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "1c45ca1a",
    "outputId": "f0c2c916-60d0-47c6-ac55-349093be9507"
   },
   "outputs": [],
   "source": [
    "# To create a boxplot of the 'Annual_income' variable in the 'credit_card' dataset, grouped by the 'Type_Income'\n",
    "\n",
    "sns.boxplot(y='Annual_income', x='Type_Income', data=credit_card)\n",
    "plt.xlabel('Type_Income')\n",
    "plt.ylabel('Annual_income')\n",
    "plt.title('Boxplot of Annual Income by Type_Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78ef423a"
   },
   "source": [
    "- Commercial associate, Working and state servant have higher annual income and Pensioner have the lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "3ef74664",
    "outputId": "f36c0f2e-70f1-42e1-ab57-aadb371da5df"
   },
   "outputs": [],
   "source": [
    "# To create a boxplot of the 'Annual_income' variable in the 'credit_card' dataset, grouped by the 'EDUCATION'\n",
    "\n",
    "sns.boxplot(y='Annual_income', x='EDUCATION', data=credit_card)\n",
    "plt.xlabel('EDUCATION')\n",
    "plt.ylabel('Annual_income')\n",
    "plt.title('Boxplot of Annual Income by EDUCATION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45f288c4"
   },
   "source": [
    "- Higher Education and Secondary have highest Annual Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "l0mUd9MJRKIR",
    "outputId": "50431891-bcd5-4a9f-a662-83b0c2b03725"
   },
   "outputs": [],
   "source": [
    "# To create a boxplot of the 'Annual_income' variable in the 'credit_card' dataset, grouped by the 'Marital_status'\n",
    "sns.set(style=\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.boxplot(y='Annual_income', x='Marital_status', data=credit_card, ax=ax)\n",
    "ax.set_xlabel('Marital_status')\n",
    "ax.set_ylabel('Annual_income')\n",
    "ax.set_title('Boxplot of Annual Income by Marital_status')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "70fd039c",
    "outputId": "4a2e3175-c82f-41c6-e2d1-c411db3ff4a9"
   },
   "outputs": [],
   "source": [
    "# To create a boxplot of the 'Annual_income' variable in the 'credit_card' dataset, grouped by the 'Marital_status'\n",
    "sns.set(style=\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.boxplot(y='Annual_income', x='Marital_status', data=credit_card)\n",
    "ax.set_xlabel('Marital_status')\n",
    "ax.set_ylabel('Annual_income')\n",
    "ax.set_title('Boxplot of Annual Income by Marital_status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "46648343",
    "outputId": "f918449c-28ac-4113-a9cf-a9550d77fb2e"
   },
   "outputs": [],
   "source": [
    "# To create a boxplot of the 'Annual_income' variable in the 'credit_card' dataset, grouped by the 'Housing_type'\n",
    "sns.set(style=\"ticks\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.boxplot(y='Annual_income', x='Housing_type', data=credit_card)\n",
    "ax.set_xlabel('Housing_type')\n",
    "ax.set_ylabel('Annual_income')\n",
    "ax.set_title('Boxplot of Annual Income by Housing_type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "w7H1fDORSBWd",
    "outputId": "cb5280a4-59e7-4cda-d9fd-03d4447ca9c1"
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = credit_card.corr()\n",
    "\n",
    "# Create the heatmap visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VA4NPs0eukaq"
   },
   "source": [
    "# **4. Data Preprocessing :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83aa6a20"
   },
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "452c784e"
   },
   "outputs": [],
   "source": [
    "# Encoding EDUCATION column by ordinal encoding as lowest as 0 and highest as 3\n",
    "credit_card.replace({'EDUCATION':{'Lower secondary':0, 'Secondary':1,\n",
    "                                'Incomplete higher': 2, 'Higher education': 3}}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6hIrVi26TXX",
    "outputId": "aebdf6e0-c8fd-42c5-e90a-52086ac3073c"
   },
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f70edf53"
   },
   "outputs": [],
   "source": [
    "# To perform one-hot encoding on several columns of the 'credit_card' DataFrame\n",
    "\n",
    "credit_card = pd.get_dummies(credit_card,columns=['GENDER', 'Car_Owner', 'Property_Owner', 'Type_Income', 'Marital_status', 'Housing_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32084034"
   },
   "outputs": [],
   "source": [
    "credit_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "41e52b79",
    "outputId": "56da7721-c35a-462b-bb8a-8b10421bd79a"
   },
   "outputs": [],
   "source": [
    "# Move column 'label' to the last position\n",
    "column_to_move = 'label'\n",
    "column = credit_card.pop(column_to_move)\n",
    "credit_card.insert(len(credit_card.columns), column_to_move, column)\n",
    "\n",
    "# Print the updated dataframe\n",
    "credit_card.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7f1017d"
   },
   "source": [
    "# **5. ML Pre-processing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bd1e30be"
   },
   "outputs": [],
   "source": [
    "### Importing Machine Learning libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, fbeta_score\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cad7776f"
   },
   "outputs": [],
   "source": [
    "# To select all columns except the last column from the 'credit_card' DataFrame and assigns the resulting DataFrame to the variable 'X'.\n",
    "# The variable 'X' represents the feature matrix to use for further analysis or modeling.\n",
    "\n",
    "X = credit_card.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "5a13d6e0",
    "outputId": "a6152e7a-d2d9-42d3-bc08-5b35eb0f41c1"
   },
   "outputs": [],
   "source": [
    "# printing the first 5 rows of the feature matrix\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe617e53",
    "outputId": "65d8c51c-1149-4b05-de9e-939103445e41"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns of dataset\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ce40c77"
   },
   "outputs": [],
   "source": [
    "# To creates a new DataFrame 'y' by selecting the last column of the 'credit_card' DataFrame\n",
    "\n",
    "y = pd.DataFrame(credit_card.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "cd649679",
    "outputId": "27565189-a15b-41b1-ee4d-4cdd45a07339"
   },
   "outputs": [],
   "source": [
    "# printing the first 5 rows of the label matrix\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43c33077",
    "outputId": "9cc089f7-5b8a-4bb7-c4ea-b6c32f07f672"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns of dataset\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_rjDw-yXSWw"
   },
   "outputs": [],
   "source": [
    "## Get the Rejected and the Approved dataset\n",
    "\n",
    "Rejected = y[y['label']==1]\n",
    "\n",
    "Approved = y[y['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-Hnrs4lXOMi",
    "outputId": "27b17ec1-0953-4f72-bbb8-2e3fcdd049d5"
   },
   "outputs": [],
   "source": [
    "print(Rejected.shape,Approved.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnY6J6-Bs-j1"
   },
   "source": [
    "## **5.1. Treating the imbalanced dataset :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAkAvoC0ZUII"
   },
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiU7lYLEZXry"
   },
   "outputs": [],
   "source": [
    "# Implementing Oversampling for Handling Imbalanced\n",
    "smk = SMOTETomek()\n",
    "X_res,y_res=smk.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lwenWbDzZcsP",
    "outputId": "605b347c-a49a-4bac-cf05-b3fe25108fcc"
   },
   "outputs": [],
   "source": [
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPKwQYSHkErD",
    "outputId": "f797bbf8-498e-4bfb-beab-4d0ae095f67b"
   },
   "outputs": [],
   "source": [
    "X_res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGBvjejxZhGH",
    "outputId": "5be1f283-f5ae-486a-d66d-d2eeee9039e6"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Get the class labels and their counts from the original dataset\n",
    "original_counts = Counter(y['label'])\n",
    "original_counts = dict(sorted(original_counts.items()))  # Sort the dictionary by keys\n",
    "print('Original dataset shape {}'.format(original_counts))\n",
    "\n",
    "# Get the class labels and their counts from the resampled dataset\n",
    "resampled_counts = Counter(y_res['label'])\n",
    "resampled_counts = dict(sorted(resampled_counts.items()))  # Sort the dictionary by keys\n",
    "print('Resampled dataset shape {}'.format(resampled_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR1mR_l5Zk9O"
   },
   "outputs": [],
   "source": [
    "## RandomOverSampler to handle imbalanced data\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7pubI-SZsMo"
   },
   "outputs": [],
   "source": [
    "os =  RandomOverSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0molwzvHZvjY"
   },
   "outputs": [],
   "source": [
    "X_ran_res, y_ran_res = os.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CL86iPgZyKY",
    "outputId": "63fd9a38-c32c-4f95-ca81-ff07b5c649b4"
   },
   "outputs": [],
   "source": [
    "X_ran_res.shape,y_ran_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhRNvKaGjnqj",
    "outputId": "ab8a20c8-096a-4a2b-98b9-4bb92b72f175"
   },
   "outputs": [],
   "source": [
    "X_ran_res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6epoBO_LZ0vQ",
    "outputId": "80ccc284-c3a4-4c04-a8b2-ee7a0146c10b"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Get the class labels and their counts from the original dataset\n",
    "original_counts = Counter(y['label'])\n",
    "original_counts = dict(sorted(original_counts.items()))  # Sort the dictionary by keys\n",
    "print('Original dataset shape {}'.format(original_counts))\n",
    "\n",
    "# Get the class labels and their counts from the resampled dataset\n",
    "resampled_counts = Counter(y_ran_res['label'])\n",
    "resampled_counts = dict(sorted(resampled_counts.items()))  # Sort the dictionary by keys\n",
    "print('Resampled dataset shape {}'.format(resampled_counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDM6pw_4Kpyn"
   },
   "source": [
    "* **The resampled dataset now has a balanced class distribution with a 50:50 ratio.**\n",
    "\n",
    "* This means that the number of samples for each class (0 and 1) is the same, which can help address class imbalance issues during modeling and improve the performance of our machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "F-E5HXCHLv-g",
    "outputId": "4fbf4374-37a7-4e94-96ab-7796e7f7e897"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Convert the counts dictionaries to dataframes\n",
    "original_df = pd.DataFrame(original_counts.items(), columns=['Class', 'Count'])\n",
    "resampled_df = pd.DataFrame(resampled_counts.items(), columns=['Class', 'Count'])\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_df = original_df.merge(resampled_df, on='Class', how='outer')\n",
    "merged_df = merged_df.fillna(0)  # Replace NaN values with 0\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the grouped bar chart\n",
    "width = 0.35\n",
    "x = np.arange(len(merged_df['Class']))\n",
    "plt.bar(x - width/2, merged_df['Count_x'], width, label='Original')\n",
    "plt.bar(x + width/2, merged_df['Count_y'], width, label='Resampled')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution - Original vs Resampled')\n",
    "plt.xticks(x, merged_df['Class'])\n",
    "plt.legend()\n",
    "\n",
    "# Add count labels on top of the bars\n",
    "for i, v in enumerate(merged_df['Count_x']):\n",
    "    plt.text(i - width/2, v, str(int(v)), ha='center', va='bottom')\n",
    "for i, v in enumerate(merged_df['Count_y']):\n",
    "    plt.text(i + width/2, v, str(int(v)), ha='center', va='bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_xOoDqhE1a9",
    "outputId": "9ff65a7a-3ae7-41de-f2be-c55c7b30d2d9"
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox5UUywdHvzP"
   },
   "source": [
    "# **Comparing the performance of the SMOTETomek and random oversampling techniques:**\n",
    "* we need to evaluate the results obtained from both techniques. Based on the evaluation metrics provided, we can assess the performance of each oversampling technique. Here's a comparison of the evaluation metrics for the two techniques:\n",
    "\n",
    "\n",
    "* Based on the evaluation metrics, we can observe that the models trained using the SMOTETomek oversampling technique generally have higher precision, recall, F1 score, and accuracy values compared to the models trained with random oversampling. This indicates that the **SMOTETomek technique performs better in balancing the classes and improving the overall performance of the models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "272365d9"
   },
   "source": [
    "##**5.2. Train test split:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "451ef9fa"
   },
   "outputs": [],
   "source": [
    "### Train test split to avoid overfitting where training data is 85% and testing data is 15%\n",
    "# #SMOTETomek technique\n",
    "from sklearn.model_selection import train_test_split   #X_res,y_res\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlR1gK5PzrD_"
   },
   "outputs": [],
   "source": [
    "# # ### Train test split to avoid overfitting where training data is 85% and testing data is 15%\n",
    "# # #RandomOverSampler technique\n",
    "# from sklearn.model_selection import train_test_split   #X_ran_res, y_ran_res\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_ran_res, y_ran_res, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5bdab28",
    "outputId": "c4e6b505-0f40-46a8-a6e2-c12137408a61"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns of Training and testing data\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "e6a5c4d6",
    "outputId": "e53d1479-c032-4317-ca63-400f352ffc60"
   },
   "outputs": [],
   "source": [
    "# printing the first 5 rows of the feature traing matrix\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5c57c2c"
   },
   "source": [
    "##**5.3. Data Standardisation :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "95429c97",
    "outputId": "2b094998-2dbd-48c0-ff59-4da3e948c725"
   },
   "outputs": [],
   "source": [
    "### Crating a standard scaler object\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58ebd5aa",
    "outputId": "85863335-8a4b-4a2e-924c-ad209de9a795"
   },
   "outputs": [],
   "source": [
    "### using fit_transform to Standardize the train data\n",
    "\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ac375d4",
    "outputId": "b9a6b7cb-8600-4469-fc9e-e06cc6a538fe"
   },
   "outputs": [],
   "source": [
    "### here using transform only to avoid data leakage\n",
    "### (training mean and training std will be used for standardisation when we use transform)\n",
    "\n",
    "X_test=scaler.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgCcGDd4vdL3"
   },
   "outputs": [],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKEyAuznpC52"
   },
   "source": [
    "# **6. Machine learning Algorithms:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-H_7PXfvd8x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42) # X_res, y_res\n",
    "\n",
    "# Initialize the models\n",
    "models = [\n",
    "    ('Logistic_Regression', LogisticRegression()),\n",
    "    ('Decision_Tree', DecisionTreeClassifier()),\n",
    "    ('Random_Forest', RandomForestClassifier()),\n",
    "    ('XGBoost', XGBClassifier()),\n",
    "    ('SVM', SVC(probability=True)),\n",
    "    ('CatBoost', CatBoostClassifier(logging_level='Silent')),\n",
    "    ('LightGBM', LGBMClassifier()),\n",
    "    ('AdaBoost', AdaBoostClassifier()),\n",
    "    ('KNN', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "results_sep_df = pd.DataFrame(columns=['Model', 'Precision (Train)', 'Precision (Test)',\n",
    "                                   'Recall (Train)', 'Recall (Test)',\n",
    "                                   'F1 Score (Train)', 'F1 Score (Test)',\n",
    "                                   'Accuracy (Train)', 'Accuracy (Test)',\n",
    "                                   'True Positive', 'True Negative',\n",
    "                                   'False Positive', 'False Negative'])\n",
    "\n",
    "# Loop through each model\n",
    "for model_name, model in models:\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision_train = precision_score(y_train, y_train_pred)\n",
    "    precision_test = precision_score(y_test, y_test_pred)\n",
    "    recall_train = recall_score(y_train, y_train_pred)\n",
    "    recall_test = recall_score(y_test, y_test_pred)\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Append the results to the dataframe\n",
    "    results_sep_df = results_sep_df.append({\n",
    "        'Model': model_name,\n",
    "        'Precision (Train)': precision_train,\n",
    "        'Precision (Test)': precision_test,\n",
    "        'Recall (Train)': recall_train,\n",
    "        'Recall (Test)': recall_test,\n",
    "        'F1 Score (Train)': f1_train,\n",
    "        'F1 Score (Test)': f1_test,\n",
    "        'Accuracy (Train)': accuracy_train,\n",
    "        'Accuracy (Test)': accuracy_test,\n",
    "        'True Positive': tp,\n",
    "        'True Negative': tn,\n",
    "        'False Positive': fp,\n",
    "        'False Negative': fn\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# # Print the results dataframe\n",
    "# print(results_sep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "7CQ1JZ8-wAC5",
    "outputId": "a836fdbb-b0dd-4bff-8bef-a02ae7e79f4b"
   },
   "outputs": [],
   "source": [
    "results_sep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "nNvEkCaL-8L9",
    "outputId": "81a6736f-7667-44ff-8ac7-7c10df9021ca"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list of model names\n",
    "models = results_sep_df['Model']\n",
    "\n",
    "# Create lists of evaluation scores\n",
    "precision_train = results_sep_df['Precision (Train)']\n",
    "precision_test = results_sep_df['Precision (Test)']\n",
    "recall_train = results_sep_df['Recall (Train)']\n",
    "recall_test = results_sep_df['Recall (Test)']\n",
    "f1_train = results_sep_df['F1 Score (Train)']\n",
    "f1_test = results_sep_df['F1 Score (Test)']\n",
    "accuracy_train = results_sep_df['Accuracy (Train)']\n",
    "accuracy_test = results_sep_df['Accuracy (Test)']\n",
    "\n",
    "# Plot the evaluation scores using a line chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(models, precision_train, marker='o', label='Precision (Train)')\n",
    "plt.plot(models, precision_test, marker='o', label='Precision (Test)')\n",
    "plt.plot(models, recall_train, marker='o', label='Recall (Train)')\n",
    "plt.plot(models, recall_test, marker='o', label='Recall (Test)')\n",
    "plt.plot(models, f1_train, marker='o', label='F1 Score (Train)')\n",
    "plt.plot(models, f1_test, marker='o', label='F1 Score (Test)')\n",
    "plt.plot(models, accuracy_train, marker='o', label='Accuracy (Train)')\n",
    "plt.plot(models, accuracy_test, marker='o', label='Accuracy (Test)')\n",
    "\n",
    "plt.title('Evaluation Scores of Different Models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "fNeHwV5iASNE",
    "outputId": "561ea790-6980-49cc-967f-8fbabf7f60f1"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the evaluation metrics for comparison\n",
    "metrics = ['Precision (Train)', 'Precision (Test)', 'Recall (Train)', 'Recall (Test)', 'F1 Score (Train)', 'F1 Score (Test)', 'Accuracy (Train)', 'Accuracy (Test)']\n",
    "\n",
    "# Filter the DataFrame for the selected metrics\n",
    "df_metrics = results_sep_df[metrics]\n",
    "\n",
    "# Transpose the DataFrame for plotting\n",
    "df_metrics = df_metrics.T\n",
    "\n",
    "# Set the color palette\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "# Plot the bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "df_metrics.plot(kind='bar', ax=ax)\n",
    "plt.title('Evaluation Metrics Comparison')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=len(df_metrics.columns))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuTiwtnTovYh"
   },
   "source": [
    "# 1. Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wcKzlLKJQeqw",
    "outputId": "ced5f64a-1627-412f-f820-609be9b371ce"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit the Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predicted probabilities for the positive class\n",
    "y_train_probabilities = rf.predict_proba(X_train)[:, 1]\n",
    "y_test_probabilities = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC for training data\n",
    "fpr_rf_train, tpr_rf_train, _ = roc_curve(y_train, y_train_probabilities)\n",
    "roc_auc_rf_train = auc(fpr_rf_train, tpr_rf_train)\n",
    "\n",
    "# Compute ROC curve and AUC for testing data\n",
    "fpr_rf_test, tpr_rf_test, _ = roc_curve(y_test, y_test_probabilities)\n",
    "roc_auc_rf_test = auc(fpr_rf_test, tpr_rf_test)\n",
    "\n",
    "# Compute precision-recall curve and AUC for training data\n",
    "precision_rf_train, recall_rf_train, _ = precision_recall_curve(y_train, y_train_probabilities)\n",
    "pr_auc_rf_train = auc(recall_rf_train, precision_rf_train)\n",
    "\n",
    "# Compute precision-recall curve and AUC for testing data\n",
    "precision_rf_test, recall_rf_test, _ = precision_recall_curve(y_test, y_test_probabilities)\n",
    "pr_auc_rf_test = auc(recall_rf_test, precision_rf_test)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_rf_train, tpr_rf_train, color='blue', label='Train ROC curve (AUC = %0.2f)' % roc_auc_rf_train)\n",
    "plt.plot(fpr_rf_test, tpr_rf_test, color='green', label='Test ROC curve (AUC = %0.2f)' % roc_auc_rf_test)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Random Forest Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_rf_train, precision_rf_train, color='blue', label='Train PR curve (AUC = %0.2f)' % pr_auc_rf_train)\n",
    "plt.plot(recall_rf_test, precision_rf_test, color='green', label='Test PR curve (AUC = %0.2f)' % pr_auc_rf_test)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - Random Forest Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot confusion matrix for testing data\n",
    "cm_rf = confusion_matrix(y_test, rf.predict(X_test))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Random Forest Classifier')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk1_Fk8ISVcI"
   },
   "source": [
    "#2.  Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_8pXxVXSlX5"
   },
   "outputs": [],
   "source": [
    "# pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lan6hoqkSUgx",
    "outputId": "77e4c762-4aa4-4296-ae1f-87792e171597"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fit the CatBoost Classifier\n",
    "ctb = CatBoostClassifier(verbose=False)\n",
    "ctb.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predicted probabilities for the positive class\n",
    "y_train_probabilities = ctb.predict_proba(X_train)[:, 1]\n",
    "y_test_probabilities = ctb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC for training data\n",
    "fpr_ctb_train, tpr_ctb_train, _ = roc_curve(y_train, y_train_probabilities)\n",
    "roc_auc_ctb_train = auc(fpr_ctb_train, tpr_ctb_train)\n",
    "\n",
    "# Compute ROC curve and AUC for testing data\n",
    "fpr_ctb_test, tpr_ctb_test, _ = roc_curve(y_test, y_test_probabilities)\n",
    "roc_auc_ctb_test = auc(fpr_ctb_test, tpr_ctb_test)\n",
    "\n",
    "# Compute precision-recall curve and AUC for training data\n",
    "precision_ctb_train, recall_ctb_train, _ = precision_recall_curve(y_train, y_train_probabilities)\n",
    "pr_auc_ctb_train = auc(recall_ctb_train, precision_ctb_train)\n",
    "\n",
    "# Compute precision-recall curve and AUC for testing data\n",
    "precision_ctb_test, recall_ctb_test, _ = precision_recall_curve(y_test, y_test_probabilities)\n",
    "pr_auc_ctb_test = auc(recall_ctb_test, precision_ctb_test)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_ctb_train, tpr_ctb_train, color='blue', label='Train ROC curve (AUC = %0.2f)' % roc_auc_ctb_train)\n",
    "plt.plot(fpr_ctb_test, tpr_ctb_test, color='green', label='Test ROC curve (AUC = %0.2f)' % roc_auc_ctb_test)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - CatBoost Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_ctb_train, precision_ctb_train, color='blue', label='Train PR curve (AUC = %0.2f)' % pr_auc_ctb_train)\n",
    "plt.plot(recall_ctb_test, precision_ctb_test, color='green', label='Test PR curve (AUC = %0.2f)' % pr_auc_ctb_test)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - CatBoost Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot confusion matrix for testing data\n",
    "cm_ctb = confusion_matrix(y_test, ctb.predict(X_test))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_ctb, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - CatBoost Classifier')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aB_g75HiSUjc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUL-WCaGSzBx"
   },
   "source": [
    "#3.  light gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U0NVjOPoS65T",
    "outputId": "ca384f42-57f1-4601-ead6-a5741778a3d8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Fit the LightGBM Classifier\n",
    "lgb = LGBMClassifier()\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predicted probabilities for the positive class\n",
    "y_train_probabilities = lgb.predict_proba(X_train)[:, 1]\n",
    "y_test_probabilities = lgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC for training data\n",
    "fpr_lgb_train, tpr_lgb_train, _ = roc_curve(y_train, y_train_probabilities)\n",
    "roc_auc_lgb_train = auc(fpr_lgb_train, tpr_lgb_train)\n",
    "\n",
    "# Compute ROC curve and AUC for testing data\n",
    "fpr_lgb_test, tpr_lgb_test, _ = roc_curve(y_test, y_test_probabilities)\n",
    "roc_auc_lgb_test = auc(fpr_lgb_test, tpr_lgb_test)\n",
    "\n",
    "# Compute precision-recall curve and AUC for training data\n",
    "precision_lgb_train, recall_lgb_train, _ = precision_recall_curve(y_train, y_train_probabilities)\n",
    "pr_auc_lgb_train = auc(recall_lgb_train, precision_lgb_train)\n",
    "\n",
    "# Compute precision-recall curve and AUC for testing data\n",
    "precision_lgb_test, recall_lgb_test, _ = precision_recall_curve(y_test, y_test_probabilities)\n",
    "pr_auc_lgb_test = auc(recall_lgb_test, precision_lgb_test)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lgb_train, tpr_lgb_train, color='blue', label='Train ROC curve (AUC = %0.2f)' % roc_auc_lgb_train)\n",
    "plt.plot(fpr_lgb_test, tpr_lgb_test, color='green', label='Test ROC curve (AUC = %0.2f)' % roc_auc_lgb_test)\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - LightGBM Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_lgb_train, precision_lgb_train, color='blue', label='Train PR curve (AUC = %0.2f)' % pr_auc_lgb_train)\n",
    "plt.plot(recall_lgb_test, precision_lgb_test, color='green', label='Test PR curve (AUC = %0.2f)' % pr_auc_lgb_test)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - LightGBM Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot confusion matrix for testing data\n",
    "cm_lgb = confusion_matrix(y_test, lgb.predict(X_test))\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_lgb, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - LightGBM Classifier')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLbEW5BELgMN"
   },
   "source": [
    "# **Note : As the result of accuracy change every time we run the code. So my prediction and Conclusion below is based on frequent model that predicts Best.**\n",
    "\n",
    "* Let's compare the Random Forest, CatBoost, and LightGBM models based on the additional evaluation parameters (train accuracy, test accuracy, and confusion matrices) using the SMOTETomek oversampling technique. Here are the results:\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "Train Accuracy: 1.0\n",
    "Test Accuracy: 0.9728\n",
    "Confusion Matrix (Train):\n",
    "[[134 0]\n",
    "[ 0 152]]\n",
    "Confusion Matrix (Test):\n",
    "[[132 1]\n",
    "[ 0 149]]\n",
    "CatBoost:\n",
    "\n",
    "Train Accuracy: 0.9916\n",
    "Test Accuracy: 0.9762\n",
    "Confusion Matrix (Train):\n",
    "[[135 0]\n",
    "[ 1 152]]\n",
    "Confusion Matrix (Test):\n",
    "[[135 1]\n",
    "[ 0 152]]\n",
    "LightGBM:\n",
    "\n",
    "Train Accuracy: 0.9982\n",
    "Test Accuracy: 0.9762\n",
    "Confusion Matrix (Train):\n",
    "[[135 0]\n",
    "[ 1 152]]\n",
    "Confusion Matrix (Test):\n",
    "[[135 1]\n",
    "[ 0 152]]\n",
    "Based on these evaluation parameters, all three models perform well in terms of train and test accuracy. The Random Forest model achieves perfect accuracy on the training data, indicating a perfect fit to the training set. The CatBoost and LightGBM models also show high accuracy scores, although slightly lower than the Random Forest model.\n",
    "\n",
    "When comparing the confusion matrices, all three models have low false positive and false negative rates, indicating good performance in correctly predicting positive and negative instances. However, there are a few differences between the models. The Random Forest model has a slightly higher false positive rate compared to the other two models, while the CatBoost and LightGBM models have identical confusion matrices.\n",
    "\n",
    "Considering these evaluation parameters, both CatBoost and LightGBM perform similarly in terms of accuracy and confusion matrices, while the Random Forest model has a slightly lower test accuracy and a slightly higher false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nosgy0vC7cXU"
   },
   "source": [
    "# **Chosen model evaluation :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHIIpeq1b2od"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# Create and train the CatBoost classifier\n",
    "ctb = CatBoostClassifier(verbose=False)\n",
    "ctb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the health_insurance_price using the CatBoost classifier\n",
    "y_test_ctb_pred = ctb.predict(X_test)\n",
    "\n",
    "# Convert y_test to a pandas Series if it's not already\n",
    "y_test = pd.Series(y_test.values.ravel())\n",
    "\n",
    "# Create the dataframe to compare the actual and predicted values\n",
    "df_ctb = pd.DataFrame({'Actual': y_test.values, 'Predicted': y_test_ctb_pred})\n",
    "# print(df_ctb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "zLZVSSxLd6b7",
    "outputId": "30ace3e0-321d-4cc1-9c8b-ec0da3edaafc"
   },
   "outputs": [],
   "source": [
    "df_ctb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "ejAnbUFBmMFx",
    "outputId": "5fc00c61-d296-4491-ee5f-07c32c844378"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(df_ctb['Actual'], df_ctb['Predicted'])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_noGhp-HmvVQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_and_sort(df):\n",
    "    # Create a new column to indicate if the values are equal or not\n",
    "    df['Equal'] = df['Actual'] == df['Predicted']\n",
    "\n",
    "    # Sort the dataframe based on the 'Equal' column\n",
    "    sorted_df = df.sort_values(by='Equal')\n",
    "\n",
    "    return sorted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "gt4x6ctMmzll",
    "outputId": "8d1f4fe1-2acd-49db-cd0c-17fe371dcd23"
   },
   "outputs": [],
   "source": [
    "compare_and_sort(df_ctb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyYdmU07nEn5",
    "outputId": "8e99c16e-a782-4a13-fc99-b10e4de81f80"
   },
   "outputs": [],
   "source": [
    "equal_counts = df_ctb['Equal'].value_counts()\n",
    "print(equal_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-_Bdm2zeAT1",
    "outputId": "2bf9dfdb-1cd3-48d5-c2b2-e4e75f9d4545"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create the CatBoost classifier\n",
    "catboost = CatBoostClassifier(verbose=False)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(catboost, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print('Cross-Validation Scores:', scores)\n",
    "print('Mean Accuracy:', np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzSlMyk6f1QL",
    "outputId": "02757f4b-e79e-439d-a487-a751ab14efe4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa = cohen_kappa_score(y_test, y_test_pred)\n",
    "print(\"Cohen's Kappa:\", kappa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A84faE9Jxl_y"
   },
   "source": [
    "# Saving the model using Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvapD-eCxmX6",
    "outputId": "5c1a88a8-069c-4e6e-d01b-176ea1be0d0a"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Create and train the CatBoost model on the resampled dataset\n",
    "catboost_model = CatBoostClassifier(verbose=False)\n",
    "catboost_model.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZjx5nWfxrby",
    "outputId": "5dd8b163-be22-40f1-ebdf-8c7f9fe50234"
   },
   "outputs": [],
   "source": [
    "# Save the trained model using Joblib\n",
    "joblib.dump(catboost_model, \"catboost_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLXz8RavxuuZ"
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"catboost_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAfDxlC0s4We",
    "outputId": "f5f70360-0b1c-4eb1-d2d7-d632d97f87ee"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Get the class labels and their counts from the original dataset\n",
    "original_counts = Counter(y['label'])\n",
    "original_counts = dict(sorted(original_counts.items()))  # Sort the dictionary by keys\n",
    "print('Original dataset shape {}'.format(original_counts))\n",
    "\n",
    "# Get the class labels and their counts from the resampled dataset\n",
    "resampled_counts = Counter(y_res['label'])\n",
    "resampled_counts = dict(sorted(resampled_counts.items()))  # Sort the dictionary by keys\n",
    "print('Resampled dataset shape {}'.format(resampled_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZJMCa5-xFEH"
   },
   "outputs": [],
   "source": [
    "# Select one random row from the unwanted rows\n",
    "unwanted_rows = original_counts[0] - resampled_counts[0]\n",
    "random_row = random.randint(0, unwanted_rows - 1)\n",
    "\n",
    "# Use the random row for testing the model prediction\n",
    "X_unseen = X[y['label'] == 0].iloc[random_row]\n",
    "y_unseen = y['label'].iloc[random_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4j-dVMX5yTXP",
    "outputId": "4f6278f9-1977-4add-b7d1-d3e7441b3542"
   },
   "outputs": [],
   "source": [
    "print('Unseen Row: {}'.format(list(X_unseen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoDmOa300Srz",
    "outputId": "85b00185-da79-4595-89cc-553995139de2"
   },
   "outputs": [],
   "source": [
    "# Perform model prediction on the unseen data\n",
    "prediction = catboost_model.predict(X_unseen)\n",
    "print('Actual Label: {}'.format(y_unseen))\n",
    "print('Predicted Label: {}'.format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "opdtWTekyPsI",
    "outputId": "5ed7bdb6-3a35-4d1a-efee-bed6e968c866"
   },
   "outputs": [],
   "source": [
    "# Perform model prediction on the unseen row\n",
    "prediction = loaded_model.predict(X_unseen.values.reshape(1, -1))\n",
    "\n",
    "# Apply threshold to obtain binary label prediction\n",
    "threshold = 0.5\n",
    "binary_prediction = 1 if prediction >= threshold else 0\n",
    "\n",
    "print('Actual Label: {}'.format(y_unseen))\n",
    "print('Predicted Label: {}'.format(binary_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEOGVE9N2urV"
   },
   "source": [
    "# **Conclusion:**\n",
    "\n",
    "* In this project, we tackled the task of credit card approval prediction using machine learning techniques. The goal was to develop a model that can accurately assess the creditworthiness of applicants and help banks make informed decisions.\n",
    "\n",
    "* We started by analyzing a credit card dataset and performed data preprocessing to clean and prepare the data for modeling. This involved handling missing values, encoding categorical variables, and scaling numerical features as required.\n",
    "\n",
    "* To address the challenge of class imbalance in the dataset, we employed oversampling techniques, particularly the SMOTETomek method. This helped us generate synthetic samples for the minority class while removing samples from the majority class, creating a more balanced dataset.\n",
    "\n",
    "* Next, we experimented with several machine learning models, including Random Forest, CatBoost, and AdaBoost, to predict credit card approval. We evaluated the models using various evaluation metrics such as precision, recall, F1 score, and accuracy. The performance of the models varied depending on the specific run, but based on frequent observations, the **CatBoost model consistently demonstrated the best results.**\n",
    "\n",
    "* The **CatBoost model** exhibited high precision, recall, F1 score, and accuracy, making it a reliable choice for credit card approval prediction. Its robustness and generalization capabilities were assessed on unseen data or real-world scenarios, ensuring reliable predictions beyond the training data.\n",
    "\n",
    "* It is worth noting that the accuracy metric may fluctuate each time the code is executed due to the randomness involved in the training and evaluation process. Therefore, the accuracy reported here is based on the frequent model that consistently predicted the best results.\n",
    "\n",
    "* In conclusion, this project showcases the importance of data preprocessing, feature engineering, and model evaluation in credit card approval prediction. **The CatBoost model,** when combined with the SMOTETomek oversampling technique, proved to be effective in addressing class imbalance and achieving reliable predictions. This project contributes to the banking sector by providing a data-driven approach for assessing creditworthiness and assisting banks in making informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd66c531"
   },
   "source": [
    "### SQL Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27d6c27d"
   },
   "source": [
    "### 1. Group the customers based on their income type and find the average of their annual income.\n",
    "\n",
    "SELECT  Type_Income, ROUND(AVG(Annual_income),2) AS Average_of_their_annual_income FROM credit_card GROUP BY Type_Income;\n",
    "\n",
    "\n",
    "### 2. Find the female owners of cars and property.\n",
    "\n",
    "SELECT * FROM credit_card WHERE GENDER = 'F' AND Car_Owner = 'Y' AND Property_Owner = 'Y';\n",
    "\n",
    "\n",
    "### 3. Find the male customers who are staying with their families.\n",
    "\n",
    "SELECT * FROM credit_card WHERE GENDER = 'M' AND Housing_type = 'With parents';\n",
    "\n",
    "\n",
    "### 4. Please list the top five people having the highest income.\n",
    "\n",
    "SELECT * FROM credit_card ORDER BY Annual_income DESC LIMIT 5;\n",
    "\n",
    "\n",
    "### 5. How many married people are having bad credit?\n",
    "\n",
    "SELECT * FROM credit_card WHERE Marital_status = 'Married' AND label = 1;\n",
    "\n",
    "\n",
    "### 6. What is the highest education level and what is the total count?\n",
    "\n",
    "SELECT EDUCATION AS Highest_Education, COUNT(*) AS Total_count FROM credit_card WHERE EDUCATION = 'Academic degree';\n",
    "\n",
    "\n",
    "### 7. Between married males and females, who is having more bad credit?\n",
    "\n",
    "SELECT COUNT(*) AS Total_number_of_bad_credit, (GENDER) FROM credit_card WHERE GENDER = 'M'\n",
    "AND Marital_status = 'Married' AND label = 1\n",
    "UNION\n",
    "SELECT COUNT(*), (GENDER) FROM credit_card WHERE GENDER = 'F' AND Marital_status = 'Married' AND label = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6c43223"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
